{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "import org.apache.spark.mllib.clustering.{KMeans, KMeansModel}\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.rdd.RDD\n\ndef isClean(row:Array[String]):Boolean = {\n    var clean = true\n    \n    if (row.length == 0) {\n        return false\n    }\n    \n    for (i <- 0 to row.length-1) {\n        clean = clean && row(i) != \"\\\"\\\"\"\n        \n    }\n    return clean\n}\n\nval data = sc.textFile(\"/resources/Final2.csv\")\nval header = data.first\nval rows = data.filter(line => line != header)\nval iter = rows.filter(e => !e.isEmpty)\nval lat = iter.map(_.split(\",\")(10).slice(3,10).toDouble)\nlat.take(10).foreach(println)\nval lon = iter.map(_.split(\",\")(11).slice(0,6).toDouble)\nval latlon = iter.map(record => Vectors.dense(record.split(\",\")(10).slice(3,10).toDouble, record.split(\",\")(11).slice(0,6).toDouble))\nval numCl = 15\nval numIter = 20\nval clusters = KMeans.train(latlon, numCl, numIter)\nval WSSSE = clusters.computeCost(latlon)\nclusters.clusterCenters", "outputs": [{"output_type": "stream", "name": "stdout", "text": "-8.6288\n-8.6059\n-8.5999\n-8.6612\n-8.6408\n-8.6529\n-8.5747\n-8.6405\n-8.6072\n-8.5701\n"}, {"execution_count": 6, "output_type": "execute_result", "data": {"text/plain": "Array([-8.60921526717557,41.14854707379145], [-7.7353,41.294], [-8.630743251533742,41.15860429447854], [-8.635166666666667,41.38683333333333], [-8.592801357466065,41.18010859728504], [-8.231850000000001,41.449], [-8.1675,41.707], [-8.603231249999999,41.11253125], [-8.575867181467178,41.154610038610045], [-8.294425,41.1985], [-8.4246,40.207], [-8.663578846153849,41.23700000000001], [-8.678935443037975,41.17501265822784], [-8.656279692307695,41.15920307692313], [-8.6141,40.918749999999996])"}, "metadata": {}}], "metadata": {"scrolled": true, "collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark 1.3.1 (Scala 2.10.4)", "name": "spark", "language": "scala"}, "language_info": {"name": "scala"}}}